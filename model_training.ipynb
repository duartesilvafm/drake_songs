{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import time\n",
    "\n",
    "from unidecode import unidecode\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from modules.char_processors import CharProcessor, OneStep\n",
    "from modules.models import CharModel, MyCallback"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>lyrics_title</th>\n",
       "      <th>lyrics_url</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Certified Lover Boy</td>\n",
       "      <td>Certified Lover Boy* Lyrics</td>\n",
       "      <td>https://genius.com/Drake-certified-lover-boy-l...</td>\n",
       "      <td>[Verse]\\nPut my feelings on ice\\nAlways been a...</td>\n",
       "      <td>8.7K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Certified Lover Boy</td>\n",
       "      <td>Like I’m Supposed To/Do Things Lyrics</td>\n",
       "      <td>https://genius.com/Drake-like-im-supposed-to-d...</td>\n",
       "      <td>[Verse]\\nHands are tied\\nSomeone's in my ear f...</td>\n",
       "      <td>38.8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Certified Lover Boy</td>\n",
       "      <td>Not Around Lyrics</td>\n",
       "      <td>https://genius.com/Drake-not-around-lyrics</td>\n",
       "      <td>[Intro]\\nYeah, we back\\nWassup ladies?\\nSwisha...</td>\n",
       "      <td>129.8K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album                           lyrics_title  \\\n",
       "0  Certified Lover Boy            Certified Lover Boy* Lyrics   \n",
       "1  Certified Lover Boy  Like I’m Supposed To/Do Things Lyrics   \n",
       "2  Certified Lover Boy                      Not Around Lyrics   \n",
       "\n",
       "                                          lyrics_url  \\\n",
       "0  https://genius.com/Drake-certified-lover-boy-l...   \n",
       "1  https://genius.com/Drake-like-im-supposed-to-d...   \n",
       "2         https://genius.com/Drake-not-around-lyrics   \n",
       "\n",
       "                                              lyrics track_views  \n",
       "0  [Verse]\\nPut my feelings on ice\\nAlways been a...        8.7K  \n",
       "1  [Verse]\\nHands are tied\\nSomeone's in my ear f...       38.8K  \n",
       "2  [Intro]\\nYeah, we back\\nWassup ladies?\\nSwisha...      129.8K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read file\n",
    "file = r'./data/drake_data.csv'\n",
    "\n",
    "# read as a csv with pandas\n",
    "# the structure of the data makes pandas the best library to read, since it contains columns\n",
    "data = pd.read_csv(file, sep = \",\")\n",
    "\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropnas in the lyrics, not interested in those\n",
    "data = data.dropna(subset = ['lyrics'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the song lyrics into a list\n",
    "drake_songs = data['lyrics'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean text\n",
    "def clean_text(song: str, line_breaks_replacement: str = ' '):\n",
    "    '''\n",
    "    Cleans a specific drake song\n",
    "\n",
    "    Args:\n",
    "        song (str): text with the lyrics of a specific song\n",
    "        line_breaks_replacement (str): character to use to replace line breaks\n",
    "\n",
    "    Returns:\n",
    "        drake_verses_joined (str): text with no line breaks and verses only sang by drake\n",
    "    '''\n",
    "\n",
    "    # remove Unicode characters\n",
    "    normalized_song = unidecode(song)\n",
    "\n",
    "    # remove line breaks\n",
    "    song_list = normalized_song.split('\\n')\n",
    "\n",
    "    # new verses\n",
    "    drake_verses = []\n",
    "    \n",
    "    # set default drake to be true\n",
    "    drake = True\n",
    "\n",
    "    # write a loop to iterate and return only the verses sung by drake\n",
    "    for verse in song_list:\n",
    "\n",
    "        if len(verse) == 0:\n",
    "            continue\n",
    "\n",
    "        # identify if its a hear by the squared brakers\n",
    "        if '[' in verse:\n",
    "\n",
    "            # update the verse_head value\n",
    "            verse_head = verse\n",
    "\n",
    "            def drake_sung(verse):\n",
    "                '''Method to identify if drake is singing the verse'''\n",
    "\n",
    "                # find a :\n",
    "                match = verse.find(':')\n",
    "\n",
    "                # when the artist is not specified its drake\n",
    "                if match == -1:\n",
    "                    return True\n",
    "\n",
    "                # else we need to check if it will be a pure drake verse\n",
    "                else:\n",
    "                    \n",
    "                    # get the list of singers\n",
    "                    singers = verse[match+2:].replace(']', '').split(' ')\n",
    "\n",
    "                    # get if drake is the only singer\n",
    "                    if ('Drake' in singers) & (len(singers) == 1):\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "\n",
    "            # bool if sung by drake\n",
    "            drake = drake_sung(verse_head)\n",
    "\n",
    "        if (drake) & ('[' not in verse):\n",
    "\n",
    "            # remove punctuation from the verse\n",
    "            clean_verse = ''.join([x.lower() for x in verse if x not in string.punctuation])\n",
    "\n",
    "            # append to the list\n",
    "            drake_verses.append(clean_verse)\n",
    "\n",
    "    # join all of drake verses\n",
    "    drake_verses_joined = ' '.join(drake_verses)\n",
    "\n",
    "    # return the new list\n",
    "    return drake_verses_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_drake = ' '.join([clean_text(song) for song in drake_songs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a json for later\n",
    "file = open('./data/drake_songs.txt', 'w')\n",
    "file.write(only_drake)\n",
    "file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 unique characters\n"
     ]
    }
   ],
   "source": [
    "# instantiante char processor class\n",
    "char_processor = CharProcessor(text=only_drake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put my feelings on ice always been a gem certified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=string, numpy=\n",
       "array([b'p', b'u', b't', b' ', b'm', b'y', b' ', b'f', b'e', b'e', b'l',\n",
       "       b'i', b'n', b'g', b's', b' ', b'o', b'n', b' ', b'i', b'c', b'e',\n",
       "       b' ', b'a', b'l', b'w', b'a', b'y', b's', b' ', b'b', b'e', b'e',\n",
       "       b'n', b' ', b'a', b' ', b'g', b'e', b'm', b' ', b'c', b'e', b'r',\n",
       "       b't', b'i', b'f', b'i', b'e', b'd'], dtype=object)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create example text and use char processor to convert to ids and convert back\n",
    "example_verse = only_drake[:50]\n",
    "print(example_verse)\n",
    "verse_chars = char_processor.ragged_tensor(example_verse)\n",
    "verse_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([27, 32, 31,  1, 24, 36,  1, 17, 16, 16, 23, 20, 25, 18, 30,  1, 26,\n",
       "       25,  1, 20, 14, 16,  1, 12, 23, 34, 12, 36, 30,  1, 13, 16, 16, 25,\n",
       "        1, 12,  1, 18, 16, 24,  1, 14, 16, 29, 31, 20, 17, 20, 16, 15],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the ids from the verse (FEED TEXT - METHOD ALREADY CREATES RAGGED TENSOR)\n",
    "ids_from_verse = char_processor.get_ids_from_text(example_verse)\n",
    "ids_from_verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'put my feelings on ice always been a gem certified'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert back to text\n",
    "chars_from_ids = char_processor.text_from_ids(ids_from_verse)\n",
    "chars_from_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, the methods from CharProcessor class are able to process a verse, convert it to tokens and convert it back to text\n",
    "\n",
    "We will now try to create a dataset using the class with the create_dataset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 40\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Specify sequence length\n",
    "SEQUENCE = 100\n",
    "\n",
    "# Dataset path\n",
    "PATH = './data/character_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(40, 100), dtype=tf.int64, name=None), TensorSpec(shape=(40, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataset, specifying the path to save, batch size and buffer size\n",
    "dataset = char_processor.create_dataset(text=only_drake, pathsave=PATH, save=True, \\\n",
    "    sequence=SEQUENCE, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE)\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.models import CharModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "VOCAB_SIZE = len(char_processor.ids_from_chars.get_vocabulary())\n",
    "EMBEDDING_DIM = 100\n",
    "LSTM_UNITS = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_units=LSTM_UNITS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try out the model unfitted, we will see that it will not be able to return any proper verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 100, 38) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'fore i make my decisions thats how i take the high road say i never get alone time thats a lie thoug'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'7uplzefgnzg4faaxwbrvoy0wety2jcp6nyhj83f5vrluwsy0xn3kqgtf0ct2fht7a9fa5zmoihz136qtrn6uumvmjpowk41c5g3c'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", char_processor.text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", char_processor.text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model exponential loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (40, 100, 38)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(3.6375577, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exponential loss: 37.99892044067383\n",
      "Vocab Size: 38\n"
     ]
    }
   ],
   "source": [
    "print(f'Exponential loss: {tf.exp(example_batch_mean_loss).numpy()}')\n",
    "print(f'Vocab Size: {VOCAB_SIZE}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the exponential of the mean loss of the untrained model, we can check whether the model has been properly initialized or not. \n",
    "\n",
    "If the exponential loss is similar to the vocab size, that means that the model has been properly initialzed (it generated characters randomly from the character pool available)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile with adam and sparse categorical crossentropy loss\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"char_model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     multiple                  3800      \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               multiple                  481200    \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               multiple                  721200    \n",
      "                                                                 \n",
      " dense_6 (Dense)             multiple                  308224    \n",
      "                                                                 \n",
      " dense_7 (Dense)             multiple                  38950     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,553,374\n",
      "Trainable params: 1,553,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "callback_loss = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "127/127 [==============================] - 172s 1s/step - loss: 2.8966\n",
      "Epoch 2/40\n",
      "127/127 [==============================] - 153s 1s/step - loss: 2.5466\n",
      "Epoch 3/40\n",
      "127/127 [==============================] - 153s 1s/step - loss: 2.1214\n",
      "Epoch 4/40\n",
      "127/127 [==============================] - 157s 1s/step - loss: 1.8520\n",
      "Epoch 5/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 1.6721\n",
      "Epoch 6/40\n",
      "127/127 [==============================] - 160s 1s/step - loss: 1.5667\n",
      "Epoch 7/40\n",
      "127/127 [==============================] - 158s 1s/step - loss: 1.4961\n",
      "Epoch 8/40\n",
      "127/127 [==============================] - 160s 1s/step - loss: 1.4443\n",
      "Epoch 9/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 1.4030\n",
      "Epoch 10/40\n",
      "127/127 [==============================] - 160s 1s/step - loss: 1.3678\n",
      "Epoch 11/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 1.3356\n",
      "Epoch 12/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 1.3056\n",
      "Epoch 13/40\n",
      "127/127 [==============================] - 156s 1s/step - loss: 1.2775\n",
      "Epoch 14/40\n",
      "127/127 [==============================] - 159s 1s/step - loss: 1.2528\n",
      "Epoch 15/40\n",
      "127/127 [==============================] - 175s 1s/step - loss: 1.2270\n",
      "Epoch 16/40\n",
      "127/127 [==============================] - 168s 1s/step - loss: 1.2019\n",
      "Epoch 17/40\n",
      "127/127 [==============================] - 160s 1s/step - loss: 1.1792\n",
      "Epoch 18/40\n",
      "127/127 [==============================] - 159s 1s/step - loss: 1.1566\n",
      "Epoch 19/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 1.1337\n",
      "Epoch 20/40\n",
      "127/127 [==============================] - 171s 1s/step - loss: 1.1097\n",
      "Epoch 21/40\n",
      "127/127 [==============================] - 156s 1s/step - loss: 1.0893\n",
      "Epoch 22/40\n",
      "127/127 [==============================] - 169s 1s/step - loss: 1.0653\n",
      "Epoch 23/40\n",
      "127/127 [==============================] - 171s 1s/step - loss: 1.0432\n",
      "Epoch 24/40\n",
      "127/127 [==============================] - 166s 1s/step - loss: 1.0237\n",
      "Epoch 25/40\n",
      "127/127 [==============================] - 144s 1s/step - loss: 1.0036\n",
      "Epoch 26/40\n",
      "127/127 [==============================] - 145s 1s/step - loss: 0.9820\n",
      "Epoch 27/40\n",
      "127/127 [==============================] - 154s 1s/step - loss: 0.9640\n",
      "Epoch 28/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 0.9465\n",
      "Epoch 29/40\n",
      "127/127 [==============================] - 158s 1s/step - loss: 0.9245\n",
      "Epoch 30/40\n",
      "127/127 [==============================] - 158s 1s/step - loss: 0.9096\n",
      "Epoch 31/40\n",
      "127/127 [==============================] - 165s 1s/step - loss: 0.8913\n",
      "Epoch 32/40\n",
      "127/127 [==============================] - 152s 1s/step - loss: 0.8726\n",
      "Epoch 33/40\n",
      "127/127 [==============================] - 152s 1s/step - loss: 0.8569\n",
      "Epoch 34/40\n",
      "127/127 [==============================] - 150s 1s/step - loss: 0.8409\n",
      "Epoch 35/40\n",
      "127/127 [==============================] - 159s 1s/step - loss: 0.8276\n",
      "Epoch 36/40\n",
      "127/127 [==============================] - 154s 1s/step - loss: 0.8128\n",
      "Epoch 37/40\n",
      "127/127 [==============================] - 155s 1s/step - loss: 0.7991\n",
      "Epoch 38/40\n",
      "127/127 [==============================] - 161s 1s/step - loss: 0.7880\n",
      "Epoch 39/40\n",
      "127/127 [==============================] - 162s 1s/step - loss: 0.7737\n",
      "Epoch 40/40\n",
      "127/127 [==============================] - 160s 1s/step - loss: 0.7620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[callback_loss, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/drake_song_generator\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/drake_song_generator\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/drake_song_generator')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Song Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them as separate variables for later\n",
    "ids_from_chars = char_processor.ids_from_chars\n",
    "chars_from_ids = char_processor.chars_from_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "\n",
    "\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "        skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            # Put a -inf at each bad index.\n",
    "            values=[-float('inf')]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            # Match the shape to the vocabulary\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())])\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convert strings to token IDs.\n",
    "        input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                            return_state=True)\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one step model\n",
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tried to be nice to you, but you pushed me away that i real why you heard or who is it imagine and im convinced i made sacrifices ive been starin at the mosto drug it right now thats me on fuck it i understand im not alone up the whole city stucked it right now that i didnt just keep it right man i play seem like im said i seen fuck the deales yeah they aint swimmen to a wife dj you think were home now cause me one my face with me when i was on a compondo eat and we takin it all bottles in houstatlantavegas ayy houstatlantavegas ayy houstatlantavegas ayy houstatlantavegas ayy houstatlanta hand ima happen that still quick wes always was a supportin man what make it friends take you the best with everybody of right thrd much on my nw flexh and im the intriggas ask hes chas to calm the things that i am over im in that bitch aint lovers again party and baby waight a floot for my last for no falls tell me hill she wanna hin whay up was good im winning to chuck with your chick wanna pol well you stay at you down are you down yeah you all \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 8.549474716186523\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "verse='I tried to be nice to you, but you pushed me away'\n",
    "next_char = tf.constant(verse, shape=(BATCH_SIZE))\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "545f545a20ef48d9ad91a95288453e1d0b46d55d89c6de3b2c98cbbf7ed52788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
